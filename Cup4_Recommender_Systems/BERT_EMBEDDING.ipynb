{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>DataLab Cup 4: Recommender Systems</center>\n",
    "<center>Shan-Hung Wu & DataLab</center>\n",
    "<center>Fall 2023</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Platform: [Kaggle](https://www.kaggle.com/t/b06e248a3827434f80c4fdc6009d5fe0)\n",
    "\n",
    "Please download the dataset and the environment source code from Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this competition, your goal is to design a recommender system that suggests news articles to users. The performance of your recommender system will be assessed using a simulation environment.\n",
    "\n",
    "At each timestep, the simulation environment randomly selects an active user with a given `user_id`. Once you receive this `user_id`, your recommender system must generate a slate **(a list of 5 distinct `item_ids` to recommend to the current user)** and pass it to the environment. The environment then uses its internal information to determine which item the user will choose from the recommended list (with some degree of stochasticity) or decide not to choose any item due to a lack of interest.\n",
    "\n",
    "Each user has a latent patience value (invisible to your recommender system), which slightly increases when an item is chosen and drastically decreases when no item is chosen in each round. If a user's patience drops below 0 or the user runs out of the time budget (2000 timesteps), the user leaves the environment. The chosen `item_id` (or `-1` if no item is chosen) and whether the current user stays (`True`) or leaves (`False`) are returned as the result of recommending a slate of items. A new user (if any) will be randomly selected for recommendations in the next timestep after the response of the current user is generated.\n",
    "\n",
    "Your recommender system should continue recommending items to the current user at each timestep as long as there are still active users in the environment. The simulation process terminates after all users have left the system.\n",
    "\n",
    "**Your goal is to maximize the session length of each user.** The session length is defined as the number of timesteps a user interacts with your recommender system before leaving the environment. The calculated session length score, normalized to the range of 0 ~ 1, will be provided by the simulation environment after the completion of the simulation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from evaluation.environment import TrainingEnvironment, TestingEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Official hyperparameters for this competition (do not modify)\n",
    "N_TRAIN_USERS = 1000\n",
    "N_TEST_USERS = 2000\n",
    "N_ITEMS = 209527\n",
    "HORIZON = 2000\n",
    "TEST_EPISODES = 5\n",
    "SLATE_SIZE = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "In this competition, we won't provide a substantial user-item interaction dataset. Instead, limited information (3 items per user) on historical interactions will be available. To train your recommender system effectively, you need to employ a recommender policy to interact with the training environment and collect additional interaction data.\n",
    "\n",
    "We will introduce the side-information datasets provided in the following sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "USER_DATA = os.path.join('dataset', 'user_data.json')\n",
    "ITEM_DATA = os.path.join('dataset', 'item_data.json')\n",
    "\n",
    "# Output file path\n",
    "OUTPUT_PATH = os.path.join('output', 'output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Data\n",
    "\n",
    "In the **training environment**, there are a total of **1000 users** identified by IDs ranging from 0 to 999. For the **testing environment**, there are **2000 users** with IDs ranging from 0 to 1999. The **testing environment includes the same 1000 users found in the training environment** (user 0 to user 999), and an additional 1000 new users (user 1000 to user 1999) are introduced.\n",
    "\n",
    "For all 2000 users, we provide you with the **past 3 clicked item IDs of each user**. Let's examine the user dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[42558, 65272, 13353]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[146057, 195688, 143652]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[67551, 85247, 33714]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[116097, 192703, 103229]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[68756, 140123, 135289]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>[95090, 131393, 130239]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>[2360, 147130, 8145]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>[99794, 138694, 157888]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>[55561, 60372, 51442]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>[125409, 77906, 124792]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   history\n",
       "0           0     [42558, 65272, 13353]\n",
       "1           1  [146057, 195688, 143652]\n",
       "2           2     [67551, 85247, 33714]\n",
       "3           3  [116097, 192703, 103229]\n",
       "4           4   [68756, 140123, 135289]\n",
       "...       ...                       ...\n",
       "1995     1995   [95090, 131393, 130239]\n",
       "1996     1996      [2360, 147130, 8145]\n",
       "1997     1997   [99794, 138694, 157888]\n",
       "1998     1998     [55561, 60372, 51442]\n",
       "1999     1999   [125409, 77906, 124792]\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user = pd.read_json(USER_DATA, lines=True)\n",
    "df_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id  history1  history2  history3\n",
      "0           0     42558     65272     13353\n",
      "1           1    146057    195688    143652\n",
      "2           2     67551     85247     33714\n",
      "3           3    116097    192703    103229\n",
      "4           4     68756    140123    135289\n",
      "...       ...       ...       ...       ...\n",
      "1995     1995     95090    131393    130239\n",
      "1996     1996      2360    147130      8145\n",
      "1997     1997     99794    138694    157888\n",
      "1998     1998     55561     60372     51442\n",
      "1999     1999    125409     77906    124792\n",
      "\n",
      "[2000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 使用 explode 函數展開 history 列\n",
    "df_user_exploded = df_user.explode('history')\n",
    "\n",
    "# 使用 cumcount 生成新的列索引\n",
    "df_user_exploded['history_index'] = df_user_exploded.groupby('user_id').cumcount() + 1\n",
    "\n",
    "# 使用 pivot 進行轉換\n",
    "df_result = df_user_exploded.pivot(index='user_id', columns='history_index', values='history')\\\n",
    "                              .reset_index()\n",
    "\n",
    "# 重新命名列名，以符合你的要求\n",
    "df_result.columns = ['user_id', 'history1', 'history2', 'history3']\n",
    "\n",
    "\n",
    "df_result['user_id'] = df_result['user_id'].astype(int)\n",
    "df_result['history1'] = df_result['history1'].astype(int)\n",
    "df_result['history2'] = df_result['history2'].astype(int)\n",
    "df_result['history3'] = df_result['history3'].astype(int)    \n",
    "\n",
    "print(df_result)\n",
    "\n",
    "# Split dataset \n",
    "df_train = tf.data.Dataset.from_tensor_slices(df_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item Data\n",
    "\n",
    "Both the training and testing environments share a common pool of **209527 items** as their item candidate pool. For the side information of these items, we provide text descriptions for each news article. The item dataset is derived from the [News Category Dataset](https://www.kaggle.com/datasets/rmisra/news-category-dataset). It's important to note that you should only use the dataset provided by us. Utilizing the original dataset, which contains extra information, will be considered as cheating. Let's explore the item dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>headline</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209522</th>\n",
       "      <td>209522</td>\n",
       "      <td>RIM CEO Thorsten Heins' 'Significant' Plans Fo...</td>\n",
       "      <td>Verizon Wireless and AT&amp;T are already promotin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209523</th>\n",
       "      <td>209523</td>\n",
       "      <td>Maria Sharapova Stunned By Victoria Azarenka I...</td>\n",
       "      <td>Afterward, Azarenka, more effusive with the pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209524</th>\n",
       "      <td>209524</td>\n",
       "      <td>Giants Over Patriots, Jets Over Colts Among  M...</td>\n",
       "      <td>Leading up to Super Bowl XLVI, the most talked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209525</th>\n",
       "      <td>209525</td>\n",
       "      <td>Aldon Smith Arrested: 49ers Linebacker Busted ...</td>\n",
       "      <td>CORRECTION: An earlier version of this story i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209526</th>\n",
       "      <td>209526</td>\n",
       "      <td>Dwight Howard Rips Teammates After Magic Loss ...</td>\n",
       "      <td>The five-time all-star center tore into his te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209527 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id                                           headline  \\\n",
       "0             0  Over 4 Million Americans Roll Up Sleeves For O...   \n",
       "1             1  American Airlines Flyer Charged, Banned For Li...   \n",
       "2             2  23 Of The Funniest Tweets About Cats And Dogs ...   \n",
       "3             3  The Funniest Tweets From Parents This Week (Se...   \n",
       "4             4  Woman Who Called Cops On Black Bird-Watcher Lo...   \n",
       "...         ...                                                ...   \n",
       "209522   209522  RIM CEO Thorsten Heins' 'Significant' Plans Fo...   \n",
       "209523   209523  Maria Sharapova Stunned By Victoria Azarenka I...   \n",
       "209524   209524  Giants Over Patriots, Jets Over Colts Among  M...   \n",
       "209525   209525  Aldon Smith Arrested: 49ers Linebacker Busted ...   \n",
       "209526   209526  Dwight Howard Rips Teammates After Magic Loss ...   \n",
       "\n",
       "                                        short_description  \n",
       "0       Health experts said it is too early to predict...  \n",
       "1       He was subdued by passengers and crew when he ...  \n",
       "2       \"Until you have a dog you don't understand wha...  \n",
       "3       \"Accidentally put grown-up toothpaste on my to...  \n",
       "4       Amy Cooper accused investment firm Franklin Te...  \n",
       "...                                                   ...  \n",
       "209522  Verizon Wireless and AT&T are already promotin...  \n",
       "209523  Afterward, Azarenka, more effusive with the pr...  \n",
       "209524  Leading up to Super Bowl XLVI, the most talked...  \n",
       "209525  CORRECTION: An earlier version of this story i...  \n",
       "209526  The five-time all-star center tore into his te...  \n",
       "\n",
       "[209527 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item = pd.read_json(ITEM_DATA, lines=True)\n",
    "df_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>headline</th>\n",
       "      <th>short_description</th>\n",
       "      <th>concat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209522</th>\n",
       "      <td>209522</td>\n",
       "      <td>RIM CEO Thorsten Heins' 'Significant' Plans Fo...</td>\n",
       "      <td>Verizon Wireless and AT&amp;T are already promotin...</td>\n",
       "      <td>RIM CEO Thorsten Heins' 'Significant' Plans Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209523</th>\n",
       "      <td>209523</td>\n",
       "      <td>Maria Sharapova Stunned By Victoria Azarenka I...</td>\n",
       "      <td>Afterward, Azarenka, more effusive with the pr...</td>\n",
       "      <td>Maria Sharapova Stunned By Victoria Azarenka I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209524</th>\n",
       "      <td>209524</td>\n",
       "      <td>Giants Over Patriots, Jets Over Colts Among  M...</td>\n",
       "      <td>Leading up to Super Bowl XLVI, the most talked...</td>\n",
       "      <td>Giants Over Patriots, Jets Over Colts Among  M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209525</th>\n",
       "      <td>209525</td>\n",
       "      <td>Aldon Smith Arrested: 49ers Linebacker Busted ...</td>\n",
       "      <td>CORRECTION: An earlier version of this story i...</td>\n",
       "      <td>Aldon Smith Arrested: 49ers Linebacker Busted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209526</th>\n",
       "      <td>209526</td>\n",
       "      <td>Dwight Howard Rips Teammates After Magic Loss ...</td>\n",
       "      <td>The five-time all-star center tore into his te...</td>\n",
       "      <td>Dwight Howard Rips Teammates After Magic Loss ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209527 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id                                           headline  \\\n",
       "0             0  Over 4 Million Americans Roll Up Sleeves For O...   \n",
       "1             1  American Airlines Flyer Charged, Banned For Li...   \n",
       "2             2  23 Of The Funniest Tweets About Cats And Dogs ...   \n",
       "3             3  The Funniest Tweets From Parents This Week (Se...   \n",
       "4             4  Woman Who Called Cops On Black Bird-Watcher Lo...   \n",
       "...         ...                                                ...   \n",
       "209522   209522  RIM CEO Thorsten Heins' 'Significant' Plans Fo...   \n",
       "209523   209523  Maria Sharapova Stunned By Victoria Azarenka I...   \n",
       "209524   209524  Giants Over Patriots, Jets Over Colts Among  M...   \n",
       "209525   209525  Aldon Smith Arrested: 49ers Linebacker Busted ...   \n",
       "209526   209526  Dwight Howard Rips Teammates After Magic Loss ...   \n",
       "\n",
       "                                        short_description  \\\n",
       "0       Health experts said it is too early to predict...   \n",
       "1       He was subdued by passengers and crew when he ...   \n",
       "2       \"Until you have a dog you don't understand wha...   \n",
       "3       \"Accidentally put grown-up toothpaste on my to...   \n",
       "4       Amy Cooper accused investment firm Franklin Te...   \n",
       "...                                                   ...   \n",
       "209522  Verizon Wireless and AT&T are already promotin...   \n",
       "209523  Afterward, Azarenka, more effusive with the pr...   \n",
       "209524  Leading up to Super Bowl XLVI, the most talked...   \n",
       "209525  CORRECTION: An earlier version of this story i...   \n",
       "209526  The five-time all-star center tore into his te...   \n",
       "\n",
       "                                                   concat  \n",
       "0       Over 4 Million Americans Roll Up Sleeves For O...  \n",
       "1       American Airlines Flyer Charged, Banned For Li...  \n",
       "2       23 Of The Funniest Tweets About Cats And Dogs ...  \n",
       "3       The Funniest Tweets From Parents This Week (Se...  \n",
       "4       Woman Who Called Cops On Black Bird-Watcher Lo...  \n",
       "...                                                   ...  \n",
       "209522  RIM CEO Thorsten Heins' 'Significant' Plans Fo...  \n",
       "209523  Maria Sharapova Stunned By Victoria Azarenka I...  \n",
       "209524  Giants Over Patriots, Jets Over Colts Among  M...  \n",
       "209525  Aldon Smith Arrested: 49ers Linebacker Busted ...  \n",
       "209526  Dwight Howard Rips Teammates After Magic Loss ...  \n",
       "\n",
       "[209527 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item['concat'] = df_item['headline'] + ' ' + df_item['short_description']\n",
    "df_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "Processing batches: 100%|████████████████████████████████████████████████████████████| 205/205 [48:27<00:00, 14.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        item_id                                           headline  \\\n",
      "0             0  Over 4 Million Americans Roll Up Sleeves For O...   \n",
      "1             1  American Airlines Flyer Charged, Banned For Li...   \n",
      "2             2  23 Of The Funniest Tweets About Cats And Dogs ...   \n",
      "3             3  The Funniest Tweets From Parents This Week (Se...   \n",
      "4             4  Woman Who Called Cops On Black Bird-Watcher Lo...   \n",
      "...         ...                                                ...   \n",
      "209522   209522  RIM CEO Thorsten Heins' 'Significant' Plans Fo...   \n",
      "209523   209523  Maria Sharapova Stunned By Victoria Azarenka I...   \n",
      "209524   209524  Giants Over Patriots, Jets Over Colts Among  M...   \n",
      "209525   209525  Aldon Smith Arrested: 49ers Linebacker Busted ...   \n",
      "209526   209526  Dwight Howard Rips Teammates After Magic Loss ...   \n",
      "\n",
      "                                        short_description  \\\n",
      "0       Health experts said it is too early to predict...   \n",
      "1       He was subdued by passengers and crew when he ...   \n",
      "2       \"Until you have a dog you don't understand wha...   \n",
      "3       \"Accidentally put grown-up toothpaste on my to...   \n",
      "4       Amy Cooper accused investment firm Franklin Te...   \n",
      "...                                                   ...   \n",
      "209522  Verizon Wireless and AT&T are already promotin...   \n",
      "209523  Afterward, Azarenka, more effusive with the pr...   \n",
      "209524  Leading up to Super Bowl XLVI, the most talked...   \n",
      "209525  CORRECTION: An earlier version of this story i...   \n",
      "209526  The five-time all-star center tore into his te...   \n",
      "\n",
      "                                                   concat  \\\n",
      "0       Over 4 Million Americans Roll Up Sleeves For O...   \n",
      "1       American Airlines Flyer Charged, Banned For Li...   \n",
      "2       23 Of The Funniest Tweets About Cats And Dogs ...   \n",
      "3       The Funniest Tweets From Parents This Week (Se...   \n",
      "4       Woman Who Called Cops On Black Bird-Watcher Lo...   \n",
      "...                                                   ...   \n",
      "209522  RIM CEO Thorsten Heins' 'Significant' Plans Fo...   \n",
      "209523  Maria Sharapova Stunned By Victoria Azarenka I...   \n",
      "209524  Giants Over Patriots, Jets Over Colts Among  M...   \n",
      "209525  Aldon Smith Arrested: 49ers Linebacker Busted ...   \n",
      "209526  Dwight Howard Rips Teammates After Magic Loss ...   \n",
      "\n",
      "                                           bert_embedding  \n",
      "0       [-0.2841511070728302, 0.08811354637145996, 0.1...  \n",
      "1       [-0.8287755846977234, -0.1098385751247406, 0.0...  \n",
      "2       [-0.7934879660606384, -0.07371799647808075, -0...  \n",
      "3       [-0.006652943789958954, -0.21324782073497772, ...  \n",
      "4       [-0.8586671352386475, -0.1649531126022339, 0.1...  \n",
      "...                                                   ...  \n",
      "209522  [-0.4451044797897339, 0.03896689787507057, 0.1...  \n",
      "209523  [-1.4245283603668213, -0.3609985411167145, 0.0...  \n",
      "209524  [-0.6930840015411377, -0.09591633081436157, -0...  \n",
      "209525  [-0.5933670401573181, -0.13217894732952118, -0...  \n",
      "209526  [-1.0908005237579346, -0.21291016042232513, 0....  \n",
      "\n",
      "[209527 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from transformers import logging, AutoTokenizer, TFAutoModel\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# 忽略transformers庫的警告\n",
    "logging.set_verbosity_warning()\n",
    "\n",
    "# 初始化一個空的欄位用於存儲BERT embeddings\n",
    "df_item['bert_embedding'] = None\n",
    "\n",
    "# 加載BERT模型\n",
    "model = TFAutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 初始化 tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 指定批次大小\n",
    "batch_size = 1024\n",
    "\n",
    "# 分批處理文本，加入tqdm顯示進度條\n",
    "for start_idx in tqdm(range(0, len(df_item), batch_size), desc=\"Processing batches\"):\n",
    "    end_idx = start_idx + batch_size\n",
    "\n",
    "    # 獲取當前批次的文本\n",
    "    current_batch = df_item['concat'].iloc[start_idx:end_idx].tolist()\n",
    "\n",
    "    # 截取每個文本的前10個單字\n",
    "    truncated_batch = [' '.join(text.split()[:10]) for text in current_batch]\n",
    "\n",
    "    # 使用 batch_encode_plus 進行編碼\n",
    "    encoding = tokenizer.batch_encode_plus(truncated_batch, return_tensors='tf', padding=True, truncation=True)\n",
    "\n",
    "    # 獲取BERT模型的輸出向量\n",
    "    with tf.device('/CPU:0'):  # 將計算移到CPU上以防止內存不足\n",
    "        outputs = model(encoding['input_ids'])\n",
    "\n",
    "    # 提取最後一層的CLS token的向量\n",
    "    bert_embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "    # 更新當前批次的 'bert_embedding'\n",
    "    for i, idx in enumerate(range(start_idx, min(end_idx, len(df_item)))):\n",
    "        df_item.at[idx, 'bert_embedding'] = bert_embeddings[i].tolist()\n",
    "\n",
    "df_item[['item_id', 'bert_embedding']].to_csv('embedding.csv', index=False)\n",
    "    \n",
    "# 顯示修改後的DataFrame\n",
    "print(df_item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Environments\n",
    "\n",
    "We offer two simulation environments in this competition: `TrainingEnvironment` and `TestingEnvironment`. The only distinction between the two environments is the number of users, with 1000 for training and 2000 for testing. All public methods for both environments behave the same since they share the same base class.\n",
    "\n",
    "**Important Note: Ensure that you collect interaction data only by accessing the environment through the designated public methods listed below. Directly accessing or modifying any file or code in the `evaluation` directory, or retrieving internal attributes and states of the environment (including all attributes / methods starting with an underscore `_`), will be considered as cheating.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Classes\n",
    "\n",
    "### <kbd>class</kbd> `TrainingEnvironment`\n",
    "Class for the training environment. Contains first 1000 users with user ID ranging from 0 to 999. \n",
    "\n",
    "### <kbd>class</kbd> `TestingEnvironment`\n",
    "Class for the testing environment. Contains all 2000 users with user ID ranging from 0 to 1999. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Public Methods\n",
    "\n",
    "**Note that both `TrainingEnvironment` and `TestingEnvironment` shares the same set of public methods.**\n",
    "\n",
    "---\n",
    "\n",
    "### <kbd>function</kbd> `reset`\n",
    "\n",
    "\n",
    "```python\n",
    "reset() → None\n",
    "```\n",
    "\n",
    "<br/>\n",
    "Reset the environment to its initial parameters and states. \n",
    "\n",
    "---\n",
    "\n",
    "### <kbd>function</kbd> `has_next_state`\n",
    "\n",
    "\n",
    "```python\n",
    "has_next_state() → bool\n",
    "```\n",
    "\n",
    "<br/>\n",
    "Verify whether the next state exists. The next state is considered to exist if there is at least one user still present in the environment. \n",
    "\n",
    "**Returns:**\n",
    "\n",
    "  - `True` if the next state exists, `False` otherwise. \n",
    "\n",
    "---\n",
    "\n",
    "### <kbd>function</kbd> `get_state`\n",
    "\n",
    "\n",
    "```python\n",
    "get_state() → int\n",
    "```\n",
    "\n",
    "<br/>\n",
    "Get the current state (the user ID of the current user). \n",
    "\n",
    "**Returns:**\n",
    " \n",
    " - <b>``int``</b>:  The user ID of the current user, or `-1` if there are no active users in the environment. \n",
    "\n",
    "---\n",
    "\n",
    "### <kbd>function</kbd> `get_response`\n",
    "\n",
    "\n",
    "```python\n",
    "get_response(slate: list) → tuple[int, bool]\n",
    "```\n",
    "\n",
    "<br/>\n",
    "Send the recommended slate (list of 5 distinct item IDs) and get the response from the current user. The internal user state will be updated according to the response, and a random user will be selected to be the next user (next state). \n",
    "\n",
    "**Args:**\n",
    " \n",
    " - <b>`slate`</b>:  `list[int]`  A list of 5 distinct item IDs to be recommended. \n",
    "\n",
    "**Returns:**\n",
    "\n",
    " - <b>`tuple[int, bool]`</b>:  The first entry indicates the `item ID` chosen by the user, or `-1` if the user decides not to choose any item.  The second entry represents whether the user is still in the environment after this interaction round. `True` if the user stays, `False` if the user leaves. \n",
    "\n",
    "**Raises:**\n",
    " \n",
    " - <b>``AssertionError``</b>:  If the slate length is not 5, contains duplicates or out-of-range item IDs, or if there are no active users in the environment. \n",
    "\n",
    "---\n",
    "\n",
    "### <kbd>function</kbd> `get_score`\n",
    "\n",
    "\n",
    "```python\n",
    "get_score() → list[float]\n",
    "```\n",
    "\n",
    "<br/>\n",
    "Get the normalized session length score (0 ~ 1) for each user. \n",
    "\n",
    "**Returns:**\n",
    " \n",
    " - <b>``list[float]``</b>:  A list containing the normalized session length score for each user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunkSVDRecommender(tf.keras.Model):\n",
    "    '''\n",
    "    Simplified Funk-SVD recommender model\n",
    "    '''\n",
    "\n",
    "    def __init__(self, m_users: int, n_items: int, embedding_size: int, learning_rate: float):\n",
    "        '''\n",
    "        Constructor of the model\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.m = m_users\n",
    "        self.n = n_items\n",
    "        self.k = embedding_size\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        # user embeddings P\n",
    "        self.P = tf.Variable(tf.keras.initializers.RandomNormal()(shape=(self.m, self.k)))\n",
    "\n",
    "        # item embeddings Q\n",
    "        self.Q = tf.Variable(tf.keras.initializers.RandomNormal()(shape=(self.n, self.k)))\n",
    "\n",
    "        # optimizer\n",
    "        self.optimizer = tf.optimizers.Adam(learning_rate=self.lr)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, user_ids: tf.Tensor, item_ids: tf.Tensor) -> tf.Tensor:\n",
    "        '''\n",
    "        Forward pass used in training and validating\n",
    "        '''\n",
    "        # dot product the user and item embeddings corresponding to the observed interaction pairs to produce predictions\n",
    "        y_pred = tf.reduce_sum(tf.gather(self.P, indices=user_ids) * tf.gather(self.Q, indices=item_ids), axis=1)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    @tf.function\n",
    "    def compute_loss(self, y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "        '''\n",
    "        Compute the MSE loss of the model\n",
    "        '''\n",
    "        loss = tf.losses.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data: tf.Tensor) -> tf.Tensor:\n",
    "        '''\n",
    "        Train the model with one batch\n",
    "        data: batched user-item interactions\n",
    "        each record in data is in the format [UserID, NewsID, Rating]\n",
    "        '''\n",
    "        user_ids = tf.cast(data[:, 0], dtype=tf.int32)\n",
    "        item_ids = tf.cast(data[:, 1], dtype=tf.int32)\n",
    "        y_true = tf.cast(data[:, 2], dtype=tf.float32)\n",
    "\n",
    "        # compute loss\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(user_ids, item_ids)\n",
    "            loss = self.compute_loss(y_true, y_pred)\n",
    "\n",
    "        # compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "\n",
    "        # update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def val_step(self, data: tf.Tensor) -> tf.Tensor:\n",
    "        '''\n",
    "        Validate the model with one batch\n",
    "        data: batched user-item interactions\n",
    "        each record in data is in the format [UserID, MovieID, Rating, Timestamp]\n",
    "        '''\n",
    "        user_ids = tf.cast(data[:, 0], dtype=tf.int32)\n",
    "        item_ids = tf.cast(data[:, 1], dtype=tf.int32)\n",
    "        y_true = tf.cast(data[:, 2], dtype=tf.float32)\n",
    "\n",
    "        # compute loss\n",
    "        y_pred = self(user_ids, item_ids)\n",
    "        loss = self.compute_loss(y_true, y_pred)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def eval_predict_onestep(self, query: tf.Tensor) -> tf.Tensor:\n",
    "        '''\n",
    "        Retrieve and return the MovieIDs of the 10 recommended movies given a query\n",
    "        You should return a tf.Tensor with shape=(10,)\n",
    "        query will be a tf.Tensor with shape=(2,) and dtype=tf.int64\n",
    "        query[0] is the UserID of the query\n",
    "        query[1] is the Timestamp of the query\n",
    "        '''\n",
    "        # dot product the selected user and all item embeddings to produce predictions\n",
    "        user_id = tf.cast(query[0], tf.int32)\n",
    "        y_pred = tf.reduce_sum(tf.gather(self.P, user_id) * self.Q, axis=1)\n",
    "\n",
    "        # select the top 10 items with highest scores in y_pred\n",
    "        y_top_10 = tf.math.top_k(y_pred, k=10).indices\n",
    "\n",
    "        return y_top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_USERS = 1000\n",
    "\n",
    "# hyperparameters\n",
    "EMBEDDING_SIZE = 256\n",
    "BATCH_SIZE = 512\n",
    "N_EPOCHS = 25\n",
    "LEARNING_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = FunkSVDRecommender(m_users=M_USERS, n_items=N_ITEMS, embedding_size=EMBEDDING_SIZE, learning_rate=LEARNING_RATE)\n",
    "\n",
    "# train the model\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    train_loss = []\n",
    "    print(f'Epoch {epoch}:')\n",
    "\n",
    "    # training\n",
    "    for data in tqdm(dataset_train, desc='Training'):\n",
    "        loss = model.train_step(data)\n",
    "        train_loss.append(loss.numpy())\n",
    "\n",
    "    # record losses\n",
    "    avg_train_loss = np.mean(train_loss)\n",
    "    avg_val_loss = np.mean(val_loss)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # print losses\n",
    "    print(f'Epoch {epoch} train_loss: {avg_train_loss:.4f}, val_loss: {avg_val_loss:.4f}\\n')\n",
    "\n",
    "# plot the training curve\n",
    "plt.plot(train_losses, label='train_loss')\n",
    "plt.plot(val_losses, label='val_loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Loss curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The implementation of the recommender algorithm is left to you. If you're in need of ideas, you can refer to the [Recommender Systems Tutorial](https://nthu-datalab.github.io/ml/labs/recommender-systems-tutorial/recommender-systems-tutorial.html) notebook in Lecture 16. Here, we'll just provide some example use cases of the public methods.\n",
    "\n",
    "**Hint:** If you're looking for inspiration, consider starting by collecting interaction data from the environment using your initial recommender policy. Afterward, improve your model with this data, and iterate through this collect-then-train loop.\n",
    "\n",
    "**Important Note: Ensure that you save your model weights after training. You will need to load a set of model weights trained exclusively on the training environment at the beginning of each test episode.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the training environment\n",
    "train_env = TrainingEnvironment()\n",
    "\n",
    "# Reset the training environment (this can be useful when you have finished one episode of simulation and do not want to re-initialize a new environment)\n",
    "train_env.reset()\n",
    "\n",
    "# Check if there exist any active users in the environment\n",
    "env_has_next_state = train_env.has_next_state()\n",
    "print(f'There is {\"still some\" if env_has_next_state else \"no\"} active users in the training environment.')\n",
    "\n",
    "# Get the current user ID\n",
    "user_id = train_env.get_state()\n",
    "print(f'The current user is user {user_id}.')\n",
    "\n",
    "# Get the response of recommending the slate to the current user\n",
    "slate = [0, 1, 2, 3, 4]\n",
    "clicked_id, in_environment = train_env.get_response(slate)\n",
    "print(f'The click result of recommending {slate} to user {user_id} is {f\"item {clicked_id}\" if clicked_id != -1 else f\"{clicked_id} (no click)\"}.')\n",
    "print(f'User {user_id} {\"is still in\" if in_environment else \"leaves\"} the environment.')\n",
    "\n",
    "# Get the normalized session length score of all users\n",
    "train_score = train_env.get_score()\n",
    "df_train_score = pd.DataFrame([[user_id, score] for user_id, score in enumerate(train_score)], columns=['user_id', 'avg_score'])\n",
    "df_train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "While testing, you are allowed to update your model. However, please adhere to the following rules:\n",
    "\n",
    "1. Follow the testing template provided below. Modify only the sections marked as `[TODO]`. Additionally, please carefully follow the instructions specified in each `[TODO]` section. Modifying other sections or not adhering to the instructions is strictly forbidden.\n",
    "\n",
    "2. Limit model updates to one testing episode. During testing-time updates, follow these steps: (a) **Load your model weights** trained exclusively on the training environment. (b) Run the testing environment and update your model with the collected data **during the testing process**. (c) Obtain the score for this testing episode and **delete your model weights since they now contain some testing information**. **You should not save the model weights trained on the testing environment for another testing episode. Doing so will be regarded as cheating.**\n",
    "\n",
    "3. Due to the randomness in the user decision process, **run the testing process 5 times** and calculate the **average session length** for each user as the final score. This part has been covered for you.\n",
    "\n",
    "After completing the testing process, remember to submit the generated `output.csv` file to the [Kaggle competition](https://www.kaggle.com/t/b06e248a3827434f80c4fdc6009d5fe0).\n",
    "\n",
    "We will illustrate the testing process with a pure random recommender below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the testing environment\n",
    "test_env = TestingEnvironment()\n",
    "scores = []\n",
    "\n",
    "# The item_ids here is for the random recommender\n",
    "item_ids = [i for i in range(N_ITEMS)]\n",
    "\n",
    "# Repeat the testing process for 5 times\n",
    "for _ in range(TEST_EPISODES):\n",
    "    # [TODO] Load your model weights here (in the beginning of each testing episode)\n",
    "    # [TODO] Code for loading your model weights...\n",
    "\n",
    "    # Start the testing process\n",
    "    with tqdm(desc='Testing') as pbar:\n",
    "        # Run as long as there exist some active users\n",
    "        while test_env.has_next_state():\n",
    "            # Get the current user id\n",
    "            cur_user = test_env.get_state()\n",
    "\n",
    "            # [TODO] Employ your recommendation policy to generate a slate of 5 distinct items\n",
    "            # [TODO] Code for generating the recommended slate...\n",
    "            # Here we provide a simple random implementation\n",
    "            slate = random.sample(item_ids, k=SLATE_SIZE)\n",
    "\n",
    "            # Get the response of the slate from the environment\n",
    "            clicked_id, in_environment = test_env.get_response(slate)\n",
    "\n",
    "            # [TODO] Update your model here (optional)\n",
    "            # [TODO] You can update your model at each step, or perform a batched update after some interval\n",
    "            # [TODO] Code for updating your model...\n",
    "\n",
    "            # Update the progress indicator\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Record the score of this testing episode\n",
    "    scores.append(test_env.get_score())\n",
    "\n",
    "    # Reset the testing environment\n",
    "    test_env.reset()\n",
    "\n",
    "    # [TODO] Delete or reset your model weights here (in the end of each testing episode)\n",
    "    # [TODO] Code for deleting your model weights...\n",
    "\n",
    "# Calculate the average scores \n",
    "avg_scores = [np.average(score) for score in zip(*scores)]\n",
    "\n",
    "# Generate a DataFrame to output the result in a .csv file\n",
    "df_result = pd.DataFrame([[user_id, avg_score] for user_id, avg_score in enumerate(avg_scores)], columns=['user_id', 'avg_score'])\n",
    "df_result.to_csv(OUTPUT_PATH, index=False)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "- Ranking of **private** leaderboard of the Kaggle competition. (80%)\n",
    "- Report. (20%)\n",
    "\n",
    "### How is the Score For Ranking Calculated:\n",
    "\n",
    "We will calculate the MAE (Mean Absolute Error) between your submitted `output.csv` and a \"ground-truth\" of all 1s. The lower the better.\n",
    "\n",
    "### Your Report Should Contain:\n",
    "\n",
    "- Models you have tried during the competition. Briefly describe the main idea of the model and the reason why you chose that model.\n",
    "- List the experiments you have done. For instance, data collecting, utilizing the user / item datasets, hyperparameters tuning, training process, and so on.\n",
    "- Discussions, lessons learned, or anything else worth mentioning.\n",
    "- **Ensure your report notebook contains your training and testing code. We will re-run your code if we find your score on Kaggle suspicious.**\n",
    "\n",
    "Please name your report as `DL_comp4_{Your Team name}_report.ipynb.` and submit your report to the eeclass system before the deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What You Can Do\n",
    "\n",
    "- Implement any recommender models.\n",
    "- Collect data through accessing the **public methods provided by the environments** (i.e. methods listed in the ***Environment Public Methods*** section) and train your model.\n",
    "- Use the provided user history data (`dataset/user_data.json`) and item text description data (`dataset/item_data.json`) as auxiliary data to aid your model training.\n",
    "- Update the model during one testing episode while **following the rules mentioned in the ***Testing*** section.**\n",
    "- You can use a pretrained text encoder if you need text embeddings for the item text descriptions. **(This is the only part you can use a pretrained model in this competition.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What You CAN NOT Do\n",
    "\n",
    "- Use any dataset other than the provided ones. Using the original News Category Dataset is also prohibited.\n",
    "- Use any pretrained recommender models.\n",
    "- Plagiarize other teams' work.\n",
    "- Hack our simulation environments. Any attempt of accessing or modifying the data files in the `evaluation` directory, modifying the source code of the environments, accessing or modifying the private attributes and methods (i.e. methods and attributes not listed in the ***Environment Public Methods*** section), not following the rules in the ***Testing*** section, or any other forbidden actions mentioned in the previous section of the notebook will be regarded as cheating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competition Timeline\n",
    "\n",
    "- 2024/01/08 (Mon): Competition launched.\n",
    "- 2024/01/15 (Mon) 08:00 (TW): Competition deadline.\n",
    "- 2024/01/16 (Tue) 12:00 (TW): Report deadline.\n",
    "- 2024/01/16 (Tue) 15:30 (TW): Top-3 teams sharing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Misra, Rishabh. \"News Category Dataset.\" arXiv preprint arXiv:2209.11429 (2022).\n",
    "2. Misra, Rishabh and Jigyasa Grover. \"Sculpting Data for ML: The first act of Machine Learning.\" ISBN 9798585463570 (2021)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
