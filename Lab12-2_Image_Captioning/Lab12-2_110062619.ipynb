{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad623b1a",
   "metadata": {},
   "source": [
    "# Lab12-2: Image Captioning\n",
    "\n",
    "In the last Lab, use a combination of convolutional neural networks to obtain the vectorial representation of images and recurrent neural networks to decode those representations into natural language sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3f1a216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ab97a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learn includes many helpful utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79daf615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140000\n",
      "./words_captcha/a0.png\n",
      "<start> t h u s <end>\n"
     ]
    }
   ],
   "source": [
    "# Store captions and image names in vectors\n",
    "all_captions = []\n",
    "all_img_name_vector = [] # 140000 images\n",
    "\n",
    "with open('./words_captcha/spec_train_val.txt') as f:\n",
    "    for line in f:\n",
    "        img_name, caption = line.strip().split()\n",
    "        all_img_name_vector.append(f'./words_captcha/{img_name}.png')\n",
    "        all_captions.append('<start> ' + ' '.join(caption) + ' <end>')\n",
    "        \n",
    "for i in range(120000, 140000):\n",
    "    all_img_name_vector.append(f'./words_captcha/a{i}.png')\n",
    "    \n",
    "print(len(all_img_name_vector)) # 140000\n",
    "print(all_img_name_vector[0])\n",
    "print(all_captions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80ac5ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum length of any caption in our dataset\n",
    "def calc_max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fa8c808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> t h u s <end>\n",
      "[2, 9, 18, 17, 6, 3]\n"
     ]
    }
   ],
   "source": [
    "# Choose the top 5000 words from the vocabulary\n",
    "top_k = 5000\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=top_k,\n",
    "                                                  oov_token=\"<unk>\",\n",
    "                                                  filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
    "tokenizer.fit_on_texts(all_captions)\n",
    "train_seqs = tokenizer.texts_to_sequences(all_captions)\n",
    "\n",
    "print(all_captions[0])\n",
    "print(train_seqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946e415b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fcab839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle captions and image_names together\n",
    "# Set a random state\n",
    "# img_name_train, caption_train = shuffle(all_img_name_vector[:100000], all_captions[:100000], random_state=514)\n",
    "# img_name_valid, caption_valid = shuffle(all_img_name_vector[100000:120000], all_captions[100000:120000], random_state=514)\n",
    "\n",
    "img_name_train, caption_train = all_img_name_vector[:100000], all_captions[:100000]\n",
    "img_name_valid, caption_valid = all_img_name_vector[100000:120000], all_captions[100000:120000]\n",
    "\n",
    "img_name_test = all_img_name_vector[120000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593f2843",
   "metadata": {},
   "source": [
    "## Create a tf.data dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c39d0e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "BUFFER_SIZE = 5000\n",
    "embedding_dim = 256\n",
    "units = 512\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "num_steps = len(img_name_train) // BATCH_SIZE\n",
    "\n",
    "IMAGE_SIZE = (160, 300)\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31f8a80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
